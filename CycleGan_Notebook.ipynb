{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty Painting with CycleGAN\n",
    "\n",
    "My introduction to GANs. Trying to recreate the code for image-to-image translation using CycleGAN for monet painting. I'm going to based off from this [Machine Learning Mastery Tutorial](https://machinelearningmastery.com/cyclegan-tutorial-with-keras/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, json, shutil\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model, losses, optimizers\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive F is Files Volume\n",
      " Volume Serial Number is 301F-B35F\n",
      "\n",
      " Directory of f:\\git\\Pretty-Paintings-With-CycleGan\\data\n",
      "\n",
      "12/30/2021  10:57 PM    <DIR>          .\n",
      "12/30/2021  10:57 PM    <DIR>          ..\n",
      "10/17/2020  01:31 PM           535,331 metadata.csv\n",
      "12/30/2021  10:57 PM    <DIR>          testA\n",
      "12/30/2021  10:57 PM    <DIR>          testB\n",
      "12/30/2021  10:57 PM    <DIR>          trainA\n",
      "12/30/2021  10:57 PM    <DIR>          trainB\n",
      "               1 File(s)        535,331 bytes\n",
      "               6 Dir(s)  128,586,522,624 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train monet length: 1072\n",
      "train photo length: 6287\n",
      "test monet length: 121\n",
      "test photo length: 751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading train Monet: 100%|██████████| 1072/1072 [00:07<00:00, 150.12it/s]\n",
      "loading train photo: 100%|██████████| 6287/6287 [00:41<00:00, 151.04it/s]\n",
      "loading test monet: 100%|██████████| 121/121 [00:00<00:00, 151.44it/s]\n",
      "loading test photo: 100%|██████████| 751/751 [00:04<00:00, 151.93it/s]\n"
     ]
    }
   ],
   "source": [
    "DataDir = \"F:\\git\\Pretty-Paintings-With-CycleGan\\data\"\n",
    "\n",
    "train_monet = glob.glob(\"data/trainA/*\")\n",
    "train_photo = glob.glob(\"data/trainB/*\")\n",
    "test_monet = glob.glob(\"data/testA/*\")\n",
    "test_photo = glob.glob(\"data/testB/*\")\n",
    "\n",
    "print(f\"train monet length: {len(train_monet)}\")\n",
    "print(f\"train photo length: {len(train_photo)}\")\n",
    "print(f\"test monet length: {len(test_monet)}\")\n",
    "print(f\"test photo length: {len(test_photo)}\")\n",
    "\n",
    "#variables to store the data\n",
    "#we're going to say 0 is monet, 1 is a photo\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "#loading in the images\n",
    "#for better pratice, should include try catch statement in case the data isn't clean\n",
    "\n",
    "#I'm going to combine the train and test datasets because it provides more data and \n",
    "#the CycleGAN architecture doesn't generate loss based on a validation set, rather it uses another GAN to generate loss function\n",
    "for img in tqdm(train_monet, desc=\"loading train Monet\"):\n",
    "    img_array = np.array(Image.open(img))\n",
    "    train_x.append(img_array)\n",
    "    #is actual money so we're going to add a 0\n",
    "    train_y.append(0)\n",
    "\n",
    "for img in tqdm(train_photo, desc=\"loading train photo\"):\n",
    "    img_array = np.array(Image.open(img))\n",
    "    train_x.append(img_array)\n",
    "    #is actual money so we're going to add a 0\n",
    "    train_y.append(1)\n",
    "\n",
    "for img in tqdm(test_monet, desc=\"loading test monet\"):\n",
    "    img_array = np.array(Image.open(img))\n",
    "    test_x.append(img_array)\n",
    "    #is actual money so we're going to add a 0\n",
    "    test_y.append(0)\n",
    "\n",
    "for img in tqdm(test_photo, desc=\"loading test photo\"):\n",
    "    img_array = np.array(Image.open(img))\n",
    "    test_x.append(img_array)\n",
    "    #is actual money so we're going to add a 0\n",
    "    test_y.append(1)\n",
    "\n",
    "#converting them to numpy arrays\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched ')' (Temp/ipykernel_18720/1183165867.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Albert\\AppData\\Local\\Temp/ipykernel_18720/1183165867.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    print(f\"test output shape: {test_y.shape)}\")\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "#verifying that data has loaded in correctly\n",
    "index = random.randint(0, len(train_x))\n",
    "plt.imshow(train_x[index])\n",
    "print(train_y[index])\n",
    "print(f\"train input shape: {train_x.shape}\")\n",
    "print(f\"train output shape: {train_x.shape}\")\n",
    "print(f\"test input shape: {test_x.shape}\")\n",
    "print(f\"test output shape: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulation methods to prevent overfitting\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image\n",
    "\n",
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image\n",
    "\n",
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36e2b9b711ac9735416cf1b47367cae76e18ef89e5c80235aa81bb46d024b6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf_gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
